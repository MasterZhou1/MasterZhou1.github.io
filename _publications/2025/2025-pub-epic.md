---
title:          "Efficient Multi-modal Large Language Models via Progressive Consistency Distillation"
date:           2025-10-01 00:01:00 +0800
selected:       false
pub:            "NeurIPS"
pub_date:       "2025"

abstract: >-
  We propose EPIC, a progressive consistency distillation framework that mitigates the training difficulty of token compression in multi-modal LLMs by enforcing token- and layer-level consistency, achieving superior efficiency, robustness, and generalization across benchmarks.


cover:          /assets/images/covers/epic.png
authors:
  - Zichen Wen
  - Shaobo Wang
  - Yufa Zhou
  - Junyuan Zhang
  - Qintong Zhang
  - Yifeng Gao
  - Zhaorun Chen
  - Bin Wang
  - Weijia Li
  - Conghui He
  - Linfeng Zhang

links:
  Paper: https://arxiv.org/abs/2510.00515
  Code: https://github.com/ZichenWen1/EPIC
  Page: https://zichenwen1.github.io/EPIC/
---
