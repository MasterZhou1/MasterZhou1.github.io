---
title:          "Efficient Multi-modal Large Language Models via Progressive Consistency Distillation"
date:           2025-10-01 00:01:00 +0800
selected:       false
pub:            "NeurIPS"
pub_date:       "2025"

abstract: >-
  We propose EPIC, a progressive consistency distillation framework that mitigates the training difficulty of token compression in multi-modal LLMs by enforcing token- and layer-level consistency, achieving superior efficiency, robustness, and generalization across benchmarks.


cover:          /assets/images/covers/epic.png
authors:
  - Zichen Wen
  - Shaobo Wang
  - Yufa Zhou
  - Junyuan Zhang
  - Qintong Zhang
  - Yifeng Gao
  - Zhaorun Chen
  - Bin Wang
  - Weijia Li
  - Conghui He
  - Linfeng Zhang

bib: |
  @inproceedings{wen2025efficient,
    title={Efficient Multi-modal Large Language Models via Progressive Consistency Distillation},
    author={Wen, Zichen and Wang, Shaobo and Zhou, Yufa and Zhang, Junyuan and Zhang, Qintong and Gao, Yifeng and Chen, Zhaorun and Wang, Bin and Li, Weijia and He, Conghui and Zhang, Linfeng},
  booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},
  year={2025},
  url={https://openreview.net/forum?id=gZjPllL9jM}
  }

links:
  Paper: https://arxiv.org/abs/2510.00515
  Code: https://github.com/ZichenWen1/EPIC
  Page: https://zichenwen1.github.io/EPIC/
---
